{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_10_A.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKEJKu_gvwKl",
        "outputId": "40f88f49-2613-472f-9c9c-818dcdaf992d"
      },
      "source": [
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 21.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 27.5MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 30kB 23.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 40kB 20.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 51kB 22.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 61kB 16.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/67/e42bd1181472c95c8cda79305df848264f2a7f62740995a46945d9797b67/sentencepiece-0.1.95-cp36-cp36m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 25.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->torchtext==0.6.0) (0.16.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
            "Installing collected packages: sentencepiece, torchtext\n",
            "  Found existing installation: torchtext 0.3.1\n",
            "    Uninstalling torchtext-0.3.1:\n",
            "      Successfully uninstalled torchtext-0.3.1\n",
            "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqV4eDdBrFlB"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn\r\n",
        "import torch.optim as optim\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "from torchtext.datasets import Multi30k\r\n",
        "from torchtext.data import Field, BucketIterator\r\n",
        "\r\n",
        "import spacy\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "import random\r\n",
        "import math\r\n",
        "import time\r\n",
        "\r\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Eev55CirUPJ"
      },
      "source": [
        "SEED = 1234\r\n",
        "\r\n",
        "random.seed(SEED)\r\n",
        "np.random.seed(SEED)\r\n",
        "torch.manual_seed(SEED)\r\n",
        "torch.cuda.manual_seed(SEED)\r\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5_Ljx1mrWxI",
        "outputId": "5d3bb78a-2f20-44f1-af14-88367eea0136"
      },
      "source": [
        "!python -m spacy download de"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 15.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (51.1.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907057 sha256=c59a20810f98f95df87a5eda5a510bc7b9507a2bb95243b2d905354f297af609\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-20ljuwqd/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.6/dist-packages/de_core_news_sm -->\n",
            "/usr/local/lib/python3.6/dist-packages/spacy/data/de\n",
            "You can now load the model via spacy.load('de')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yIpHpq5trYTI"
      },
      "source": [
        "spacy_de = spacy.load('de')\r\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hS6XK3MqraiQ"
      },
      "source": [
        "def tokenize_de(text):\r\n",
        "  return [tok.text for tok in spacy_de.tokenizer(text)]\r\n",
        "\r\n",
        "def tokenize_en(text):\r\n",
        "  return [tok.text for tok in spacy_en.tokenizer(text)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvOGD4SBrc2f"
      },
      "source": [
        "SRC = Field(\r\n",
        "    tokenize = tokenize_en,\r\n",
        "    init_token = '<sos>',\r\n",
        "    eos_token = '<eos>',\r\n",
        "    lower = True\r\n",
        ")\r\n",
        "\r\n",
        "TRG = Field(\r\n",
        "    tokenize = tokenize_de,\r\n",
        "    init_token = '<sos>',\r\n",
        "    eos_token = '<eos>',\r\n",
        "    lower = True\r\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvvf3oZcreZ_",
        "outputId": "f03f0db3-a739-431c-cab4-f16b594279a5"
      },
      "source": [
        "train_data, valid_data, test_data = Multi30k.splits(exts=('.en', '.de'), fields=(SRC, TRG))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading training.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:01<00:00, 973kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading validation.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 273kB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "downloading mmt_task1_test2016.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 267kB/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv-P7ji8rftv"
      },
      "source": [
        "SRC.build_vocab(train_data, min_freq=2)\r\n",
        "TRG.build_vocab(train_data, min_freq=2)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHJJKry5rj3n",
        "outputId": "1ff345a0-13fc-46ab-b406-adee5c712232"
      },
      "source": [
        "BATCH_SIZE = 256\r\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
        "print(f'Device: {device}')\r\n",
        "\r\n",
        "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\r\n",
        "    (train_data, valid_data, test_data),\r\n",
        "    batch_size = BATCH_SIZE,\r\n",
        "    device = device\r\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQq3sE1rrlEY"
      },
      "source": [
        "class Encoder(torch.nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout):\r\n",
        "    super().__init__()\r\n",
        "    self.embedding = torch.nn.Embedding(input_dim, emb_dim)\r\n",
        "    self.rnn = torch.nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\r\n",
        "    self.fc = torch.nn.Linear(enc_hid_dim * 2, dec_hid_dim)\r\n",
        "    self.dropout = torch.nn.Dropout(dropout)\r\n",
        "\r\n",
        "  def forward(self, src):\r\n",
        "\r\n",
        "    # src -> [src len, batch size]\r\n",
        "\r\n",
        "    embedded = self.dropout(self.embedding(src))\r\n",
        "    # embedded -> [src len, batch size, emb_dim]\r\n",
        "\r\n",
        "    outputs, hidden = self.rnn(embedded)\r\n",
        "    # outputs -> [src len, batch size, enc_hid_dim * num_directions]\r\n",
        "    #         -> [src len, batch size, enc_hid_dim * 2]\r\n",
        "    # hidden -> [num_layers * num_directions, batch size, enc_hid_dim]\r\n",
        "    #        -> [2, batch size, enc_hid_dim]\r\n",
        "\r\n",
        "    concatenated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]),dim=1)\r\n",
        "    # concatenated -> [batch size, enc_hid_dim * 2]\r\n",
        "\r\n",
        "    hidden = torch.tanh(self.fc(concatenated))\r\n",
        "    # hidden -> [batch size, dec_hid_him]\r\n",
        "\r\n",
        "    return outputs, hidden"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vdGQvE7rm2f"
      },
      "source": [
        "class Attention(torch.nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, enc_hid_dim, dec_hid_dim):\r\n",
        "    super().__init__()\r\n",
        "    self.attn = torch.nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\r\n",
        "    self.v = torch.nn.Linear(dec_hid_dim, 1, bias=False)\r\n",
        "\r\n",
        "  def forward(self, encoder_outputs, hidden):\r\n",
        "\r\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\r\n",
        "    # hidden -> [batch size, dec_hid_dim]\r\n",
        "\r\n",
        "    src_len = encoder_outputs.shape[0]\r\n",
        "    batch_size = encoder_outputs.shape[1]\r\n",
        "\r\n",
        "    # Repeat hidden state for each time step in src len\r\n",
        "    hidden = hidden.unsqueeze(0).repeat(src_len, 1, 1)\r\n",
        "    # hidden -> [src len, batch size, dec_hid_dim]\r\n",
        "\r\n",
        "    concatenated = torch.cat((encoder_outputs, hidden), dim=2)\r\n",
        "    # concatenated -> [src len, batch size, (enc_hid_dim * 2) + dec_hid_dim]\r\n",
        "\r\n",
        "    energy = torch.tanh(self.attn(concatenated))\r\n",
        "    # energy -> [src len, batch size, dec_hid_dim]\r\n",
        "\r\n",
        "    attention = self.v(energy).squeeze(2)\r\n",
        "    # attention -> [src len, batch size]\r\n",
        "\r\n",
        "    return F.softmax(attention, dim=0)\r\n",
        "    # return dim -> [src len, batch size]\r\n",
        "    # the `src len` values of each item in batch add up to 1 (because of softmax)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yqZe3JCru9H"
      },
      "source": [
        "class Decoder(torch.nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.output_dim = output_dim\r\n",
        "\r\n",
        "    self.embedding = torch.nn.Embedding(output_dim, emb_dim)\r\n",
        "    self.rnn = torch.nn.GRU(emb_dim + (2 * enc_hid_dim), dec_hid_dim)\r\n",
        "    self.fc = torch.nn.Linear(emb_dim + dec_hid_dim + (2 * enc_hid_dim), output_dim)\r\n",
        "    self.dropout = torch.nn.Dropout(dropout)\r\n",
        "    self.attn = attention\r\n",
        "\r\n",
        "  def forward(self, input, encoder_outputs, hidden):\r\n",
        "    \r\n",
        "    # input -> [batch size]\r\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\r\n",
        "    # hidden -> [batch size, dec_hid_dim]\r\n",
        "\r\n",
        "    input = input.unsqueeze(0)\r\n",
        "    # input -> [1, batch size]\r\n",
        "\r\n",
        "    embedded = self.dropout(self.embedding(input))\r\n",
        "    # embedded -> [1, batch size, emb_dim]\r\n",
        "\r\n",
        "    a = self.attn(encoder_outputs, hidden)\r\n",
        "    # a -> [src len, batch size]\r\n",
        "\r\n",
        "    encoder_outputs = encoder_outputs.permute(1, 0, 2)\r\n",
        "    # encoder_outputs -> [batch size, src len, enc_hid_dim * 2]\r\n",
        "\r\n",
        "    a = a.permute(1, 0).unsqueeze(1)\r\n",
        "    # a -> [batch size, 1, src len]\r\n",
        "\r\n",
        "    weighted = torch.bmm(a, encoder_outputs).permute(1, 0, 2)\r\n",
        "    # weighted -> [1, batch size, enc_hid_dim * 2]\r\n",
        "\r\n",
        "    outputs, hidden = self.rnn(torch.cat((embedded, weighted), dim=2), hidden.unsqueeze(0))\r\n",
        "    # outputs -> [1, batch size, dec_hid_dim]\r\n",
        "    # hidden -> [1, batch size, dec_hid_dim]\r\n",
        "\r\n",
        "    fc_input = torch.cat((embedded, outputs, weighted), dim=2)\r\n",
        "    # fc_input -> [1, batch size, emb_dim + dec_hid_dim + (2 * enc_hid_dim)]\r\n",
        "\r\n",
        "    predictions = self.fc(fc_input).squeeze(0)\r\n",
        "    # predictions -> [batch size, output_dim]\r\n",
        "\r\n",
        "    return predictions, hidden.squeeze(0)\r\n",
        "    # return dimensions\r\n",
        "    # predictions -> [batch size, output_dim]\r\n",
        "    # hidden -> [batch size, dec_hid_dim]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aa_Uf5Cmr0b3"
      },
      "source": [
        "class Seq2Seq(torch.nn.Module):\r\n",
        "\r\n",
        "  def __init__(self, encoder, decoder, device):\r\n",
        "    super().__init__()\r\n",
        "\r\n",
        "    self.encoder = encoder\r\n",
        "    self.decoder = decoder\r\n",
        "    self.device = device\r\n",
        "\r\n",
        "  def forward(self, src, trg, teacher_forcing_ratio=0.5):\r\n",
        "\r\n",
        "    # src -> [src len, batch size]\r\n",
        "    # trg -> [trg len, batch size]\r\n",
        "\r\n",
        "    batch_size = trg.shape[1]\r\n",
        "    trg_len = trg.shape[0]\r\n",
        "    trg_vocab_size = self.decoder.output_dim\r\n",
        "\r\n",
        "    # decoder outputs\r\n",
        "    outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\r\n",
        "\r\n",
        "    # pass src through encoder\r\n",
        "    encoder_outputs, hidden = self.encoder(src)\r\n",
        "    # encoder_outputs -> [src len, batch size, enc_hid_dim * 2]\r\n",
        "    # hidden -> [batch size, dec_hid_him]\r\n",
        "\r\n",
        "    input = trg[0, :]\r\n",
        "    # input -> [batch size]\r\n",
        "\r\n",
        "    for t in range(1, trg_len):\r\n",
        "\r\n",
        "      output, hidden = self.decoder(input, encoder_outputs, hidden)\r\n",
        "      # output -> [batch size, output_dim]\r\n",
        "      # hidden -> [batch size, dec_hid_dim]\r\n",
        "\r\n",
        "      outputs[t] = output\r\n",
        "\r\n",
        "      teacher_force = random.random() < teacher_forcing_ratio\r\n",
        "\r\n",
        "      top1 = output.argmax(1)\r\n",
        "      # top1 -> [batch size]\r\n",
        "\r\n",
        "      input = trg[t] if teacher_force else top1\r\n",
        "\r\n",
        "    return outputs"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5aVqfNXr2LH"
      },
      "source": [
        "def init_weights(m):\r\n",
        "  for name, param in m.named_parameters():\r\n",
        "    if 'weight' in name:\r\n",
        "      torch.nn.init.normal_(param.data, mean=0, std=0.01)\r\n",
        "    else:\r\n",
        "      torch.nn.init.constant_(param.data, 0)\r\n",
        "\r\n",
        "def count_parameters(model):\r\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "  elapsed_time = end_time - start_time\r\n",
        "  elapsed_mins = int(elapsed_time / 60)\r\n",
        "  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "  return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CM_UztYlr3fH",
        "outputId": "15bc8581-a527-4c62-e779-0c49b68666ee"
      },
      "source": [
        "INPUT_DIM = len(SRC.vocab)\r\n",
        "OUTPUT_DIM = len(TRG.vocab)\r\n",
        "ENC_EMB_DIM = 128\r\n",
        "DEC_EMB_DIM = 128\r\n",
        "ENC_HID_DIM = 128\r\n",
        "DEC_HID_HIM = 128\r\n",
        "\r\n",
        "DROPOUT = 0.2\r\n",
        "\r\n",
        "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_HIM, DROPOUT)\r\n",
        "attn = Attention(ENC_HID_DIM, DEC_HID_HIM)\r\n",
        "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_HIM, DROPOUT, attn)\r\n",
        "\r\n",
        "model = Seq2Seq(enc, dec, device).to(device)\r\n",
        "model.apply(init_weights)\r\n",
        "\r\n",
        "print(f'Model parameters: {count_parameters(model):,}')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model parameters: 6,267,183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DbIYRRRr46f",
        "outputId": "d3060462-ff5b-40ac-e6e5-651cea4ea8e9"
      },
      "source": [
        "model"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seq2Seq(\n",
              "  (encoder): Encoder(\n",
              "    (embedding): Embedding(5893, 128)\n",
              "    (rnn): GRU(128, 128, bidirectional=True)\n",
              "    (fc): Linear(in_features=256, out_features=128, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embedding): Embedding(7855, 128)\n",
              "    (rnn): GRU(384, 128)\n",
              "    (fc): Linear(in_features=512, out_features=7855, bias=True)\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "    (attn): Attention(\n",
              "      (attn): Linear(in_features=384, out_features=128, bias=True)\n",
              "      (v): Linear(in_features=128, out_features=1, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o9477AyCr6MH"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters())"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4cAV0Gvr7gn"
      },
      "source": [
        "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\r\n",
        "criterion = torch.nn.CrossEntropyLoss(ignore_index=TRG_PAD_IDX)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV6tTKXAr9qQ"
      },
      "source": [
        "def train(model, iterator, optimizer, criterion, clip):\r\n",
        "    \r\n",
        "    model.train()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\r\n",
        "        \r\n",
        "        src = batch.src\r\n",
        "        trg = batch.trg\r\n",
        "        \r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        output = model(src, trg)\r\n",
        "        \r\n",
        "        #trg = [trg len, batch size]\r\n",
        "        #output = [trg len, batch size, output dim]\r\n",
        "        \r\n",
        "        output_dim = output.shape[-1]\r\n",
        "        \r\n",
        "        output = output[1:].view(-1, output_dim)\r\n",
        "        trg = trg[1:].view(-1)\r\n",
        "        \r\n",
        "        #trg = [(trg len - 1) * batch size]\r\n",
        "        #output = [(trg len - 1) * batch size, output dim]\r\n",
        "        \r\n",
        "        loss = criterion(output, trg)\r\n",
        "        \r\n",
        "        loss.backward()\r\n",
        "        \r\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\r\n",
        "        \r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cU6n7DjDr-8g"
      },
      "source": [
        "def evaluate(model, iterator, criterion):\r\n",
        "    \r\n",
        "    model.eval()\r\n",
        "    \r\n",
        "    epoch_loss = 0\r\n",
        "    \r\n",
        "    with torch.no_grad():\r\n",
        "    \r\n",
        "        for i, batch in tqdm(enumerate(iterator), total=len(iterator)):\r\n",
        "\r\n",
        "            src = batch.src\r\n",
        "            trg = batch.trg\r\n",
        "\r\n",
        "            output = model(src, trg, 0) #turn off teacher forcing\r\n",
        "\r\n",
        "            #trg = [trg len, batch size]\r\n",
        "            #output = [trg len, batch size, output dim]\r\n",
        "\r\n",
        "            output_dim = output.shape[-1]\r\n",
        "            \r\n",
        "            output = output[1:].view(-1, output_dim)\r\n",
        "            trg = trg[1:].view(-1)\r\n",
        "\r\n",
        "            #trg = [(trg len - 1) * batch size]\r\n",
        "            #output = [(trg len - 1) * batch size, output dim]\r\n",
        "\r\n",
        "            loss = criterion(output, trg)\r\n",
        "\r\n",
        "            epoch_loss += loss.item()\r\n",
        "        \r\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYQ6RMghsApX",
        "outputId": "6b4be071-e790-40f7-de32-d3fc941fa9a6"
      },
      "source": [
        "N_EPOCHS = 20\r\n",
        "CLIP = 1\r\n",
        "\r\n",
        "best_valid_loss = float('inf')\r\n",
        "\r\n",
        "for epoch in range(N_EPOCHS):\r\n",
        "    \r\n",
        "    start_time = time.time()\r\n",
        "    \r\n",
        "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP)\r\n",
        "    valid_loss = evaluate(model, valid_iterator, criterion)\r\n",
        "    \r\n",
        "    end_time = time.time()\r\n",
        "    \r\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "    \r\n",
        "    if valid_loss < best_valid_loss:\r\n",
        "        best_valid_loss = valid_loss\r\n",
        "        torch.save(model.state_dict(), 'tut3-model.pt')\r\n",
        "    \r\n",
        "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\r\n",
        "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.10it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.27it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 01 | Time: 0m 37s\n",
            "\tTrain Loss: 5.917 | Train PPL: 371.170\n",
            "\t Val. Loss: 5.209 |  Val. PPL: 182.953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.12it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.20it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 02 | Time: 0m 36s\n",
            "\tTrain Loss: 4.866 | Train PPL: 129.738\n",
            "\t Val. Loss: 5.155 |  Val. PPL: 173.309\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.10it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.27it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 03 | Time: 0m 37s\n",
            "\tTrain Loss: 4.574 | Train PPL:  96.904\n",
            "\t Val. Loss: 5.054 |  Val. PPL: 156.578\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.07it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.08it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 04 | Time: 0m 37s\n",
            "\tTrain Loss: 4.428 | Train PPL:  83.796\n",
            "\t Val. Loss: 5.089 |  Val. PPL: 162.284\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.07it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 05 | Time: 0m 37s\n",
            "\tTrain Loss: 4.309 | Train PPL:  74.358\n",
            "\t Val. Loss: 5.044 |  Val. PPL: 155.017\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.04it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.26it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 06 | Time: 0m 37s\n",
            "\tTrain Loss: 4.165 | Train PPL:  64.380\n",
            "\t Val. Loss: 4.980 |  Val. PPL: 145.538\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.07it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.19it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 07 | Time: 0m 37s\n",
            "\tTrain Loss: 4.001 | Train PPL:  54.646\n",
            "\t Val. Loss: 4.844 |  Val. PPL: 126.914\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.06it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.27it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 08 | Time: 0m 37s\n",
            "\tTrain Loss: 3.833 | Train PPL:  46.214\n",
            "\t Val. Loss: 4.641 |  Val. PPL: 103.667\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.06it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.29it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 09 | Time: 0m 37s\n",
            "\tTrain Loss: 3.680 | Train PPL:  39.628\n",
            "\t Val. Loss: 4.411 |  Val. PPL:  82.313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.11it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.29it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 10 | Time: 0m 37s\n",
            "\tTrain Loss: 3.493 | Train PPL:  32.882\n",
            "\t Val. Loss: 4.126 |  Val. PPL:  61.926\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.08it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.37it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 11 | Time: 0m 37s\n",
            "\tTrain Loss: 3.280 | Train PPL:  26.577\n",
            "\t Val. Loss: 3.978 |  Val. PPL:  53.426\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.03it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.37it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 12 | Time: 0m 38s\n",
            "\tTrain Loss: 3.120 | Train PPL:  22.646\n",
            "\t Val. Loss: 3.811 |  Val. PPL:  45.178\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.07it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.35it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 13 | Time: 0m 37s\n",
            "\tTrain Loss: 2.951 | Train PPL:  19.121\n",
            "\t Val. Loss: 3.617 |  Val. PPL:  37.215\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.09it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.38it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 14 | Time: 0m 37s\n",
            "\tTrain Loss: 2.794 | Train PPL:  16.349\n",
            "\t Val. Loss: 3.509 |  Val. PPL:  33.409\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.08it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.35it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 15 | Time: 0m 37s\n",
            "\tTrain Loss: 2.618 | Train PPL:  13.713\n",
            "\t Val. Loss: 3.475 |  Val. PPL:  32.286\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.08it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.30it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 16 | Time: 0m 37s\n",
            "\tTrain Loss: 2.515 | Train PPL:  12.369\n",
            "\t Val. Loss: 3.401 |  Val. PPL:  29.990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:36<00:00,  3.08it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.32it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 17 | Time: 0m 37s\n",
            "\tTrain Loss: 2.399 | Train PPL:  11.011\n",
            "\t Val. Loss: 3.320 |  Val. PPL:  27.668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.06it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.17it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 18 | Time: 0m 37s\n",
            "\tTrain Loss: 2.277 | Train PPL:   9.745\n",
            "\t Val. Loss: 3.318 |  Val. PPL:  27.598\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.06it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.21it/s]\n",
            "  0%|          | 0/114 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 19 | Time: 0m 37s\n",
            "\tTrain Loss: 2.204 | Train PPL:   9.058\n",
            "\t Val. Loss: 3.306 |  Val. PPL:  27.264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 114/114 [00:37<00:00,  3.06it/s]\n",
            "100%|██████████| 4/4 [00:00<00:00,  9.31it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 20 | Time: 0m 37s\n",
            "\tTrain Loss: 2.105 | Train PPL:   8.206\n",
            "\t Val. Loss: 3.272 |  Val. PPL:  26.363\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXxecONksCHh",
        "outputId": "cac02733-3937-47a6-aace-b83deabc9707"
      },
      "source": [
        "model.load_state_dict(torch.load('tut3-model.pt'))\r\n",
        "\r\n",
        "test_loss = evaluate(model, test_iterator, criterion)\r\n",
        "\r\n",
        "print(f'| Test Loss: {test_loss:.3f} |  Test PPL: {math.exp(test_loss):7.3f} |')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4/4 [00:00<00:00, 10.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "| Test Loss: 3.224 |  Test PPL:  25.141 |\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqeWpWHksD6h"
      },
      "source": [
        "def display_attention(sentence, translation, attention):\r\n",
        "\r\n",
        "  fig = plt.figure(figsize=(10, 10))\r\n",
        "  ax = fig.add_subplot(111)\r\n",
        "\r\n",
        "  attention = attention.squeeze(1).cpu().detach().numpy()\r\n",
        "\r\n",
        "  cax = ax.matshow(attention, cmap='bone')\r\n",
        "\r\n",
        "  ax.tick_params(labelsize=15)\r\n",
        "  ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], rotation=45)\r\n",
        "  ax.set_yticklabels(['']+translation)\r\n",
        "\r\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "  plt.show()\r\n",
        "  plt.close()"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gaOFmFhsE_6",
        "outputId": "f5e6227b-d3d8-400d-8247-370ad4dd709d"
      },
      "source": [
        "example_idx = 12\r\n",
        "\r\n",
        "src = vars(train_data.examples[example_idx])['src']\r\n",
        "trg = vars(train_data.examples[example_idx])['trg']\r\n",
        "\r\n",
        "print(f'src: ${src}')\r\n",
        "print(f'trg: ${trg}')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src: $['a', 'black', 'dog', 'and', 'a', 'spotted', 'dog', 'are', 'fighting']\n",
            "trg: $['ein', 'schwarzer', 'hund', 'und', 'ein', 'gefleckter', 'hund', 'kämpfen', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3Pi9OA5sGhv"
      },
      "source": [
        "\r\n",
        "def translate_sentence(sentence, src_field, trg_field, model, device, max_len=50):\r\n",
        "\r\n",
        "  model.eval()\r\n",
        "\r\n",
        "  if isinstance(sentence, str):\r\n",
        "    nlp = spacy.load('en')\r\n",
        "    tokens = [token.text.lower() for token in nlp(sentence)]\r\n",
        "  else:\r\n",
        "    tokens = [token.lower() for token in sentence]\r\n",
        "\r\n",
        "  tokens = [src_field.init_token] + tokens + [src_field.eos_token]\r\n",
        "\r\n",
        "  src_indexes = [src_field.vocab.stoi[token] for token in tokens]\r\n",
        "\r\n",
        "  src_tensor = torch.LongTensor(src_indexes).unsqueeze(1).to(device)\r\n",
        "\r\n",
        "  with torch.no_grad():\r\n",
        "    encoder_outputs, hidden = model.encoder(src_tensor)\r\n",
        "\r\n",
        "  trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\r\n",
        "\r\n",
        "  for i in range(max_len):\r\n",
        "\r\n",
        "    trg_tensor = torch.LongTensor([trg_indexes[-1]]).to(device)\r\n",
        "\r\n",
        "    with torch.no_grad():\r\n",
        "      output, hidden = model.decoder(trg_tensor, encoder_outputs, hidden)\r\n",
        "\r\n",
        "      pred_token = output.argmax(1).item()\r\n",
        "\r\n",
        "      trg_indexes.append(pred_token)\r\n",
        "\r\n",
        "      if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\r\n",
        "        break\r\n",
        "\r\n",
        "  trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\r\n",
        "\r\n",
        "  return trg_tokens"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlVQNC8isH8x",
        "outputId": "6c3131b5-1d10-43b7-ad6d-2a3b6b654a0f"
      },
      "source": [
        "translate_sentence(src, SRC, TRG, model, device)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<sos>',\n",
              " 'ein',\n",
              " 'schwarzer',\n",
              " 'hund',\n",
              " 'und',\n",
              " 'ein',\n",
              " 'gefleckter',\n",
              " 'hund',\n",
              " 'kämpfen',\n",
              " 'spielerisch',\n",
              " 'kämpfen',\n",
              " 'miteinander',\n",
              " '.',\n",
              " '<eos>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Ekj3hVPsJkg",
        "outputId": "42544f6a-93b1-478c-959b-764e50d828f4"
      },
      "source": [
        "from torchtext.data.metrics import bleu_score\r\n",
        "\r\n",
        "def calculate_bleu(data, src_field, trg_field, model, device, max_len = 50):\r\n",
        "\r\n",
        "  trgs = []\r\n",
        "  pred_trgs = []\r\n",
        "\r\n",
        "  for datum in data:\r\n",
        "\r\n",
        "    src = vars(datum)['src']\r\n",
        "    trg = vars(datum)['trg']\r\n",
        "\r\n",
        "    pred_trg = translate_sentence(src, SRC, TRG, model, device, max_len)\r\n",
        "\r\n",
        "    pred_trg = pred_trg[:-1]\r\n",
        "\r\n",
        "    pred_trgs.append(pred_trg)\r\n",
        "    trgs.append([trg])\r\n",
        "\r\n",
        "  return bleu_score(pred_trgs, trgs)\r\n",
        "\r\n",
        "bleu_score = calculate_bleu(test_data, SRC, TRG, model, device)\r\n",
        "\r\n",
        "print(f'BLEU score = {bleu_score*100:.2f}')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BLEU score = 22.66\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}